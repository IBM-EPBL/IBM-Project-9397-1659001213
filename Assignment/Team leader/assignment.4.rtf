{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang16393{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 6.2.9200}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9\par
import pandas as pd\par
import seaborn as sns\par
import matplotlib.pyplot as plt\par
import numpy as np\par
d=pd.read_csv("Mall_Customers.csv")\par
d=d.rename(columns = \{'Annual Income (k$)' : 'Annual_Income','Spending Score (1-100)' : 'Spending_Score'\})\par
d.head()\par
CustomerID\tab Gender\tab Age\tab Annual_Income\tab Spending_Score\par
0\tab 1\tab Male\tab 19\tab 15\tab 39\par
1\tab 2\tab Male\tab 21\tab 15\tab 81\par
2\tab 3\tab Female\tab 20\tab 16\tab 6\par
3\tab 4\tab Female\tab 23\tab 16\tab 77\par
4\tab 5\tab Female\tab 31\tab 17\tab 40\par
d.shape\par
(200, 5)\par
d.info()\par
RangeIndex: 200 entries, 0 to 199\par
Data columns (total 5 columns):\par
 #   Column          Non-Null Count  Dtype \par
---  ------          --------------  ----- \par
 0   CustomerID      200 non-null    int64 \par
 1   Gender          200 non-null    object\par
 2   Age             200 non-null    int64 \par
 3   Annual_Income   200 non-null    int64 \par
 4   Spending_Score  200 non-null    int64 \par
dtypes: int64(4), object(1)\par
memory usage: 7.9+ KB\par
sns.barplot(d.Age)\par
C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\par
  warnings.warn(\par
\par
sns.boxplot(y=d.Gender,x=d.Age)\par
\par
sns.pairplot(d)\par
\par
d.describe(include='all')\par
CustomerID\tab Gender\tab Age\tab Annual_Income\tab Spending_Score\par
count\tab 200.000000\tab 200\tab 200.000000\tab 200.000000\tab 200.000000\par
unique\tab NaN\tab 2\tab NaN\tab NaN\tab NaN\par
top\tab NaN\tab Female\tab NaN\tab NaN\tab NaN\par
freq\tab NaN\tab 112\tab NaN\tab NaN\tab NaN\par
mean\tab 100.500000\tab NaN\tab 38.850000\tab 60.560000\tab 50.200000\par
std\tab 57.879185\tab NaN\tab 13.969007\tab 26.264721\tab 25.823522\par
min\tab 1.000000\tab NaN\tab 18.000000\tab 15.000000\tab 1.000000\par
25%\tab 50.750000\tab NaN\tab 28.750000\tab 41.500000\tab 34.750000\par
50%\tab 100.500000\tab NaN\tab 36.000000\tab 61.500000\tab 50.000000\par
75%\tab 150.250000\tab NaN\tab 49.000000\tab 78.000000\tab 73.000000\par
max\tab 200.000000\tab NaN\tab 70.000000\tab 137.000000\tab 99.000000\par
d.isnull().sum()\par
CustomerID        0\par
Gender            0\par
Age               0\par
Annual_Income     0\par
Spending_Score    0\par
dtype: int64\par
sns.boxplot(d['Annual_Income'])\par
C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\par
  warnings.warn(\par
\par
q1 = d.Annual_Income.quantile(0.25)\par
q2 = d.Annual_Income.quantile(0.75)\par
IQR = q2 - q1\par
print(IQR)\par
36.5\par
d=d[~((d.Annual_Income<(q1-1.5*IQR))|(d.Annual_Income>(q2+1.5*IQR)))]\par
d\par
CustomerID\tab Gender\tab Age\tab Annual_Income\tab Spending_Score\par
0\tab 1\tab Male\tab 19\tab 15\tab 39\par
1\tab 2\tab Male\tab 21\tab 15\tab 81\par
2\tab 3\tab Female\tab 20\tab 16\tab 6\par
3\tab 4\tab Female\tab 23\tab 16\tab 77\par
4\tab 5\tab Female\tab 31\tab 17\tab 40\par
...\tab ...\tab ...\tab ...\tab ...\tab ...\par
193\tab 194\tab Female\tab 38\tab 113\tab 91\par
194\tab 195\tab Female\tab 47\tab 120\tab 16\par
195\tab 196\tab Female\tab 35\tab 120\tab 79\par
196\tab 197\tab Female\tab 45\tab 126\tab 28\par
197\tab 198\tab Male\tab 32\tab 126\tab 74\par
198 rows \'d7 5 columns\par
\par
sns.boxplot(d['Annual_Income'])\par
C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\par
  warnings.warn(\par
\par
"Checking for Categorical columns and perform Encoding"\par
d.head()\par
CustomerID\tab Gender\tab Age\tab Annual_Income\tab Spending_Score\par
0\tab 1\tab Male\tab 19\tab 15\tab 39\par
1\tab 2\tab Male\tab 21\tab 15\tab 81\par
2\tab 3\tab Female\tab 20\tab 16\tab 6\par
3\tab 4\tab Female\tab 23\tab 16\tab 77\par
4\tab 5\tab Female\tab 31\tab 17\tab 40\par
from sklearn.preprocessing import LabelEncoder\par
\par
le = LabelEncoder()\par
d.Gender = le.fit_transform(d.Gender)\par
\par
d.head()\par
C:\\Users\\KeshavG\\AppData\\Local\\Temp\\ipykernel_15040\\674852927.py:4: SettingWithCopyWarning: \par
A value is trying to be set on a copy of a slice from a DataFrame.\par
Try using .loc[row_indexer,col_indexer] = value instead\par
\par
See the caveats in the documentation: {{\field{\*\fldinst{HYPERLINK https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy }}{\fldrslt{https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ul0\cf0}}}}\f0\fs22\par
  d.Gender = le.fit_transform(d.Gender)\par
CustomerID\tab Gender\tab Age\tab Annual_Income\tab Spending_Score\par
0\tab 1\tab 1\tab 19\tab 15\tab 39\par
1\tab 2\tab 1\tab 21\tab 15\tab 81\par
2\tab 3\tab 0\tab 20\tab 16\tab 6\par
3\tab 4\tab 0\tab 23\tab 16\tab 77\par
4\tab 5\tab 0\tab 31\tab 17\tab 40\par
"Scaling the data"\par
'Scaling the data'\par
from sklearn.preprocessing import MinMaxScaler\par
scaler = MinMaxScaler()\par
data_scaled = scaler.fit_transform(d)\par
data_scaled[0:5]\par
array([[0.        , 1.        , 0.01923077, 0.        , 0.3877551 ],\par
       [0.00507614, 1.        , 0.05769231, 0.        , 0.81632653],\par
       [0.01015228, 0.        , 0.03846154, 0.00900901, 0.05102041],\par
       [0.01522843, 0.        , 0.09615385, 0.00900901, 0.7755102 ],\par
       [0.02030457, 0.        , 0.25      , 0.01801802, 0.39795918]])\par
"Performing any of the clustering algorithms"\par
'Performing any of the clustering algorithms'\par
from sklearn.cluster import KMeans\par
km = KMeans()\par
res = km.fit_predict(data_scaled)\par
res\par
array([5, 5, 0, 0, 0, 0, 6, 0, 7, 0, 7, 0, 6, 0, 5, 5, 0, 5, 7, 0, 5, 5,\par
       6, 5, 6, 5, 6, 5, 6, 0, 7, 0, 7, 5, 6, 0, 6, 0, 6, 0, 6, 5, 7, 0,\par
       6, 0, 6, 0, 0, 0, 6, 5, 0, 7, 6, 7, 6, 7, 0, 7, 7, 5, 6, 6, 7, 5,\par
       6, 6, 5, 0, 7, 6, 6, 6, 7, 5, 6, 7, 0, 6, 7, 5, 7, 6, 0, 7, 6, 0,\par
       0, 6, 6, 5, 7, 6, 0, 5, 6, 0, 7, 5, 0, 6, 7, 5, 7, 0, 6, 7, 7, 7,\par
       7, 0, 3, 5, 0, 0, 6, 6, 6, 6, 4, 3, 2, 4, 3, 2, 1, 4, 1, 4, 1, 4,\par
       3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 3, 2, 1, 4, 1, 2, 3, 4, 1, 4, 3, 2,\par
       3, 2, 1, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 2, 3, 4, 1, 4, 1, 4, 3, 2,\par
       1, 4, 1, 4, 3, 2, 1, 2, 3, 4, 3, 4, 3, 2, 3, 2, 1, 2, 3, 2, 3, 4])\par
data1 = pd.DataFrame(data_scaled, columns = d.columns)\par
data1.drop('CustomerID',axis=1,inplace=True)\par
data1.head()\par
Gender\tab Age\tab Annual_Income\tab Spending_Score\par
0\tab 1.0\tab 0.019231\tab 0.000000\tab 0.387755\par
1\tab 1.0\tab 0.057692\tab 0.000000\tab 0.816327\par
2\tab 0.0\tab 0.038462\tab 0.009009\tab 0.051020\par
3\tab 0.0\tab 0.096154\tab 0.009009\tab 0.775510\par
4\tab 0.0\tab 0.250000\tab 0.018018\tab 0.397959\par
data1['kclus']  = pd.Series(res)\par
data1.head()\par
Gender\tab Age\tab Annual_Income\tab Spending_Score\tab kclus\par
0\tab 1.0\tab 0.019231\tab 0.000000\tab 0.387755\tab 5\par
1\tab 1.0\tab 0.057692\tab 0.000000\tab 0.816327\tab 5\par
2\tab 0.0\tab 0.038462\tab 0.009009\tab 0.051020\tab 0\par
3\tab 0.0\tab 0.096154\tab 0.009009\tab 0.775510\tab 0\par
4\tab 0.0\tab 0.250000\tab 0.018018\tab 0.397959\tab 0\par
data1['kclus'].unique()\par
array([5, 0, 6, 7, 3, 4, 2, 1])\par
data1['kclus'].value_counts()\par
6    36\par
0    34\par
7    26\par
5    23\par
2    22\par
3    20\par
1    19\par
4    18\par
Name: kclus, dtype: int64\par
"Splitting dataset into train and test data"\par
'Splitting dataset into train and test data'\par
import matplotlib.pyplot as plt\par
\par
fig,ax = plt.subplots(figsize=(15,8))\par
sns.scatterplot(x=data1['Annual_Income'],\par
                y=data1['Spending_Score'],\par
                hue=data1['kclus'],\par
                palette='PuBuGn')\par
plt.show()\par
\par
ind = data1.iloc[:,0:4]\par
ind.head()\par
Gender\tab Age\tab Annual_Income\tab Spending_Score\par
0\tab 1.0\tab 0.019231\tab 0.000000\tab 0.387755\par
1\tab 1.0\tab 0.057692\tab 0.000000\tab 0.816327\par
2\tab 0.0\tab 0.038462\tab 0.009009\tab 0.051020\par
3\tab 0.0\tab 0.096154\tab 0.009009\tab 0.775510\par
4\tab 0.0\tab 0.250000\tab 0.018018\tab 0.397959\par
dep = data1.iloc[:,4:]\par
dep.head()\par
kclus\par
0\tab 5\par
1\tab 5\par
2\tab 0\par
3\tab 0\par
4\tab 0\par
from sklearn.model_selection import train_test_split\par
x_train,x_test,y_train,y_test = train_test_split(ind,dep,test_size=0.3,random_state=1)\par
x_train.head()\par
Gender\tab Age\tab Annual_Income\tab Spending_Score\par
124\tab 0.0\tab 0.096154\tab 0.495495\tab 0.285714\par
97\tab 0.0\tab 0.173077\tab 0.405405\tab 0.500000\par
42\tab 1.0\tab 0.576923\tab 0.216216\tab 0.357143\par
17\tab 1.0\tab 0.038462\tab 0.054054\tab 0.663265\par
5\tab 0.0\tab 0.076923\tab 0.018018\tab 0.765306\par
x_test.head()\par
Gender\tab Age\tab Annual_Income\tab Spending_Score\par
175\tab 0.0\tab 0.230769\tab 0.657658\tab 0.867347\par
40\tab 0.0\tab 0.903846\tab 0.207207\tab 0.346939\par
34\tab 0.0\tab 0.596154\tab 0.162162\tab 0.132653\par
90\tab 0.0\tab 0.961538\tab 0.396396\tab 0.551020\par
145\tab 1.0\tab 0.192308\tab 0.558559\tab 0.979592\par
y_train.head()\par
kclus\par
124\tab 3\par
97\tab 0\par
42\tab 7\par
17\tab 5\par
5\tab 0\par
y_test.head()\par
kclus\par
175\tab 2\par
40\tab 6\par
34\tab 6\par
90\tab 6\par
145\tab 4\par
from sklearn.linear_model import LinearRegression\par
lr = LinearRegression()\par
lr.fit(x_train,y_train)\par
LinearRegression()\par
pred_test = lr.predict(x_test)\par
pred_test[0:5]\par
array([[1.95607883],\par
       [6.1003241 ],\par
       [4.2268214 ],\par
       [6.19632985],\par
       [3.59948696]])\par
"Measuring the performance using metrics"\par
'Measuring the performance using metrics'\par
from sklearn.metrics import mean_squared_error,mean_absolute_error\par
from sklearn.metrics import accuracy_score\par
mse = mean_squared_error(pred_test,y_test)\par
print("The Mean squared error is: ", mse)\par
rmse = np.sqrt(mse)\par
print("The Root mean squared error is: ", rmse)\par
mae = mean_absolute_error(pred_test,y_test)\par
print("The Mean absolute error is: ", mae)\par
acc = lr.score(x_test,y_test)\par
print("The accuracy is: ", acc)\par
The Mean squared error is:  3.554960484338881\par
The Root mean squared error is:  1.8854602844766795\par
The Mean absolute error is:  1.4605015236480232\par
The accuracy is:  0.42996491276023463\par
 \par
}
 